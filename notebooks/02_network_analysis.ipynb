{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FASE 2: An√°lisis Relacional - ACTUALIZADO\n",
    "## Streaming Platform - User-Content Connections & Community Detection\n",
    "\n",
    "**Objetivo:** Analizar las conexiones entre usuarios y contenido para identificar comunidades y patrones de co-visualizaci√≥n.\n",
    "\n",
    "**Datos:** Datos reales de la carpeta `analyst`:\n",
    "- `integrated_data.csv` - Conexiones usuario-contenido con m√©tricas de inter√©s\n",
    "- `country_aggregated.csv` - Datos agregados por pa√≠s y criptomoneda\n",
    "- `trends_enriched.csv` - Patrones de tendencias temporales\n",
    "\n",
    "**Adaptaci√≥n:** Criptomonedas ‚Üí Categor√≠as de contenido de streaming\n",
    "- Bitcoin ‚Üí Drama\n",
    "- Ethereum ‚Üí Comedy\n",
    "- BNB ‚Üí Action\n",
    "- Solana ‚Üí Documentary\n",
    "- Tether ‚Üí Romance\n",
    "\n",
    "**Audiencia:** Equipo de algoritmos de recomendaci√≥n\n",
    "**Acci√≥n:** Personalizar algoritmos por comunidad y optimizar recomendaciones\n",
    "**Formato:** Presentaci√≥n t√©cnica (m√°ximo 10 slides)\n",
    "\n",
    "**NOTA:** Esta versi√≥n usa solo Python est√°ndar para m√°xima compatibilidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# CELDA 1: Imports y configuraci√≥n (solo Python est√°ndar)\n",
    "# ======================================================================\n",
    "\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "from collections import defaultdict, Counter\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"‚úÖ Imports cargados (solo Python est√°ndar)\")\n",
    "print(\"‚úÖ Listo para an√°lisis relacional con datos reales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# CELDA 2: Mapeo de datos y configuraci√≥n\n",
    "# ======================================================================\n",
    "\n",
    "# Mapeo de criptomonedas a categor√≠as de contenido\n",
    "crypto_to_content = {\n",
    "    'Bitcoin': 'Drama',\n",
    "    'Ethereum': 'Comedy', \n",
    "    'BNB': 'Action',\n",
    "    'Solana': 'Documentary',\n",
    "    'Tether': 'Romance'\n",
    "}\n",
    "\n",
    "# Mapeo de pa√≠ses a regiones de mercado\n",
    "country_to_region = {\n",
    "    'US': 'North America',\n",
    "    'CN': 'Asia',\n",
    "    'JP': 'Asia',\n",
    "    'DE': 'Europe',\n",
    "    'GB': 'Europe',\n",
    "    'IN': 'Asia',\n",
    "    'BR': 'South America',\n",
    "    'CA': 'North America',\n",
    "    'AU': 'Oceania',\n",
    "    'KR': 'Asia'\n",
    "}\n",
    "\n",
    "print(\"Mapeo de datos para an√°lisis relacional:\")\n",
    "print(\"Criptomonedas ‚Üí Contenido:\")\n",
    "for crypto, content in crypto_to_content.items():\n",
    "    print(f\"  {crypto} ‚Üí {content}\")\n",
    "print()\n",
    "print(\"Pa√≠ses ‚Üí Regiones de Mercado:\")\n",
    "for country, region in country_to_region.items():\n",
    "    print(f\"  {country} ‚Üí {region}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# CELDA 3: Carga de datos desde la carpeta analyst\n",
    "# ======================================================================\n",
    "\n",
    "def load_analyst_data():\n",
    "    \"\"\"Cargar datos desde los archivos de la carpeta analyst\"\"\"\n",
    "    \n",
    "    # 1. Cargar datos integrados para conexiones usuario-contenido\n",
    "    user_content_data = []\n",
    "    try:\n",
    "        with open('analyst/integrated_data.csv', 'r', encoding='utf-8') as file:\n",
    "            reader = csv.DictReader(file)\n",
    "            for row in reader:\n",
    "                if row['crypto'] in crypto_to_content:\n",
    "                    user_content_data.append({\n",
    "                        'user_id': f\"{row['country_code']}_{row['country']}\",\n",
    "                        'country': row['country'],\n",
    "                        'country_code': row['country_code'],\n",
    "                        'crypto': row['crypto'],\n",
    "                        'content_category': crypto_to_content[row['crypto']],\n",
    "                        'interest': float(row['interest']),\n",
    "                        'region': country_to_region.get(row['country_code'], 'Other'),\n",
    "                        'close_price': float(row['Close']),\n",
    "                        'volume': float(row['Volume']),\n",
    "                        'returns': float(row['returns']),\n",
    "                        'volatility_7d': float(row['volatility_7d']),\n",
    "                        'date': row['Date']\n",
    "                    })\n",
    "    except Exception as e:\n",
    "        print(f\"Error cargando integrated_data.csv: {e}\")\n",
    "    \n",
    "    # 2. Cargar datos agregados para an√°lisis de comunidades\n",
    "    community_data = []\n",
    "    try:\n",
    "        with open('analyst/country_aggregated.csv', 'r', encoding='utf-8') as file:\n",
    "            reader = csv.DictReader(file)\n",
    "            for row in reader:\n",
    "                if row['crypto'] in crypto_to_content:\n",
    "                    community_data.append({\n",
    "                        'country_code': row['country_code'],\n",
    "                        'country_name': row['name'],\n",
    "                        'crypto': row['crypto'],\n",
    "                        'content_category': crypto_to_content[row['crypto']],\n",
    "                        'interest_mean': float(row['interest_mean']),\n",
    "                        'interest_max': float(row['interest_max']),\n",
    "                        'volatility_7d_mean': float(row['volatility_7d_mean']),\n",
    "                        'close_mean': float(row['Close_mean']),\n",
    "                        'region': country_to_region.get(row['country_code'], 'Other')\n",
    "                    })\n",
    "    except Exception as e:\n",
    "        print(f\"Error cargando country_aggregated.csv: {e}\")\n",
    "    \n",
    "    return user_content_data, community_data\n",
    "\n",
    "# Cargar datos\n",
    "print(\"üîó CARGANDO DATOS PARA AN√ÅLISIS RELACIONAL...\")\n",
    "print(\"=\"*60)\n",
    "user_content_data, community_data = load_analyst_data()\n",
    "\n",
    "if user_content_data and community_data:\n",
    "    print(f\"\\nüìä Resumen de datos cargados:\")\n",
    "    print(f\"  Conexiones usuario-contenido: {len(user_content_data)} registros\")\n",
    "    print(f\"  Datos de comunidades: {len(community_data)} registros\")\n",
    "    print(f\"  Usuarios √∫nicos: {len(set(d['user_id'] for d in user_content_data))}\")\n",
    "    print(f\"  Categor√≠as de contenido: {sorted(set(d['content_category'] for d in user_content_data))}\")\n",
    "    print(f\"  Regiones: {sorted(set(d['region'] for d in user_content_data))}\")\n",
    "else:\n",
    "    print(\"‚ùå Error: No se pudieron cargar los datos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# CELDA 4: NETWORK GRAPH - Conexiones Usuario-Contenido\n",
    "# ======================================================================\n",
    "\n",
    "print(\"üï∏Ô∏è NETWORK GRAPH: Conexiones Usuario-Contenido\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "class SimpleGraph:\n",
    "    def __init__(self):\n",
    "        self.nodes = {}\n",
    "        self.edges = []\n",
    "    \n",
    "    def add_node(self, node_id, **attributes):\n",
    "        self.nodes[node_id] = attributes\n",
    "    \n",
    "    def add_edge(self, node1, node2, weight=1.0, **attributes):\n",
    "        self.edges.append((node1, node2, weight, attributes))\n",
    "    \n",
    "    def get_neighbors(self, node):\n",
    "        neighbors = []\n",
    "        for edge in self.edges:\n",
    "            if edge[0] == node:\n",
    "                neighbors.append((edge[1], edge[2]))\n",
    "            elif edge[1] == node:\n",
    "                neighbors.append((edge[0], edge[2]))\n",
    "        return neighbors\n",
    "    \n",
    "    def degree_centrality(self, node):\n",
    "        return len(self.get_neighbors(node)) / max(1, len(self.nodes) - 1)\n",
    "    \n",
    "    def density(self):\n",
    "        n = len(self.nodes)\n",
    "        if n <= 1:\n",
    "            return 0\n",
    "        return len(self.edges) / (n * (n - 1) / 2)\n",
    "\n",
    "def create_network_graph(user_content_data):\n",
    "    \"\"\"Crear grafo de red de conexiones usuario-contenido\"\"\"\n",
    "    \n",
    "    G = SimpleGraph()\n",
    "    \n",
    "    # Agregar nodos de usuarios\n",
    "    users = set(d['user_id'] for d in user_content_data)\n",
    "    for user in users:\n",
    "        user_data = next(d for d in user_content_data if d['user_id'] == user)\n",
    "        G.add_node(user, type='user', region=user_data['region'], country=user_data['country'])\n",
    "    \n",
    "    # Agregar nodos de contenido\n",
    "    content_categories = set(d['content_category'] for d in user_content_data)\n",
    "    for content in content_categories:\n",
    "        G.add_node(content, type='content')\n",
    "    \n",
    "    # Agregar aristas basadas en conexiones fuertes\n",
    "    for data in user_content_data:\n",
    "        if data['interest'] > 30:  # Umbral de conexi√≥n fuerte\n",
    "            connection_strength = data['interest'] / 100.0\n",
    "            G.add_edge(data['user_id'], data['content_category'], \n",
    "                      weight=connection_strength, \n",
    "                      interest=data['interest'],\n",
    "                      volatility=data['volatility_7d'])\n",
    "    \n",
    "    return G\n",
    "\n",
    "# Crear grafo de red\n",
    "network_graph = create_network_graph(user_content_data)\n",
    "\n",
    "print(f\"üìä Estad√≠sticas del grafo de red:\")\n",
    "print(f\"  Nodos: {len(network_graph.nodes)}\")\n",
    "print(f\"  Aristas: {len(network_graph.edges)}\")\n",
    "print(f\"  Densidad: {network_graph.density():.3f}\")\n",
    "\n",
    "# Calcular centralidad de contenido\n",
    "print(\"\\nüìà Contenido m√°s influyente (por centralidad de grado):\")\n",
    "content_centrality = {}\n",
    "content_categories = set(d['content_category'] for d in user_content_data)\n",
    "for content in content_categories:\n",
    "    centrality = network_graph.degree_centrality(content)\n",
    "    content_centrality[content] = centrality\n",
    "    print(f\"  {content}: {centrality:.3f}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Grafo de red creado con {len(network_graph.nodes)} nodos y {len(network_graph.edges)} aristas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# CELDA 5: COMMUNITY DETECTION - Clusters de Usuarios\n",
    "# ======================================================================\n",
    "\n",
    "print(\"üë• COMMUNITY DETECTION: Clusters de Usuarios\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def detect_communities(user_content_data):\n",
    "    \"\"\"Detectar comunidades basadas en preferencias de contenido\"\"\"\n",
    "    \n",
    "    communities = defaultdict(list)\n",
    "    user_preferences = defaultdict(list)\n",
    "    \n",
    "    # Agrupar preferencias por usuario\n",
    "    for data in user_content_data:\n",
    "        if data['interest'] > 25:  # Umbral de preferencia\n",
    "            user_preferences[data['user_id']].append({\n",
    "                'content': data['content_category'],\n",
    "                'interest': data['interest'],\n",
    "                'region': data['region'],\n",
    "                'volatility': data['volatility_7d']\n",
    "            })\n",
    "    \n",
    "    # Crear comunidades basadas en patrones de preferencia\n",
    "    community_id = 0\n",
    "    for user, preferences in user_preferences.items():\n",
    "        if len(preferences) > 0:\n",
    "            # Ordenar preferencias por inter√©s\n",
    "            preferences.sort(key=lambda x: x['interest'], reverse=True)\n",
    "            \n",
    "            # Crear clave de comunidad basada en top 2 preferencias\n",
    "            top_preferences = [p['content'] for p in preferences[:2]]\n",
    "            pref_key = tuple(sorted(top_preferences))\n",
    "            \n",
    "            if pref_key not in communities:\n",
    "                communities[pref_key] = {\n",
    "                    'id': community_id,\n",
    "                    'users': [],\n",
    "                    'preferred_content': list(pref_key),\n",
    "                    'size': 0,\n",
    "                    'avg_interest': 0,\n",
    "                    'regions': defaultdict(int),\n",
    "                    'avg_volatility': 0\n",
    "                }\n",
    "                community_id += 1\n",
    "            \n",
    "            communities[pref_key]['users'].append(user)\n",
    "            communities[pref_key]['size'] += 1\n",
    "            \n",
    "            # Agregar informaci√≥n de regi√≥n\n",
    "            user_region = preferences[0]['region']\n",
    "            communities[pref_key]['regions'][user_region] += 1\n",
    "            \n",
    "            # Calcular inter√©s promedio\n",
    "            total_interest = sum(p['interest'] for p in preferences)\n",
    "            communities[pref_key]['avg_interest'] += total_interest\n",
    "            \n",
    "            # Calcular volatilidad promedio\n",
    "            total_volatility = sum(p['volatility'] for p in preferences)\n",
    "            communities[pref_key]['avg_volatility'] += total_volatility\n",
    "    \n",
    "    # Calcular promedios finales\n",
    "    for community in communities.values():\n",
    "        if community['size'] > 0:\n",
    "            community['avg_interest'] /= community['size']\n",
    "            community['avg_volatility'] /= community['size']\n",
    "    \n",
    "    return list(communities.values())\n",
    "\n",
    "# Detectar comunidades\n",
    "communities = detect_communities(user_content_data)\n",
    "\n",
    "print(f\"‚úÖ Detectadas {len(communities)} comunidades\")\n",
    "\n",
    "print(\"\\nüìä An√°lisis de Comunidades:\")\n",
    "for community in communities:\n",
    "    print(f\"\\nüî∏ Comunidad {community['id']}:\")\n",
    "    print(f\"  Tama√±o: {community['size']} usuarios\")\n",
    "    print(f\"  Contenido preferido: {community['preferred_content']}\")\n",
    "    print(f\"  Inter√©s promedio: {community['avg_interest']:.1f}\")\n",
    "    print(f\"  Volatilidad promedio: {community['avg_volatility']:.3f}\")\n",
    "    \n",
    "    # Mostrar distribuci√≥n por regi√≥n\n",
    "    print(f\"  Distribuci√≥n por regi√≥n:\")\n",
    "    for region, count in community['regions'].items():\n",
    "        percentage = (count / community['size']) * 100\n",
    "        print(f\"    {region}: {count} usuarios ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\n‚úÖ An√°lisis de comunidades completado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# CELDA 6: FORCE-DIRECTED GRAPH - Visualizaci√≥n de Conexiones\n",
    "# ======================================================================\n",
    "\n",
    "print(\"‚ö° FORCE-DIRECTED GRAPH: Visualizaci√≥n de Conexiones\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def create_force_directed_data(network_graph):\n",
    "    \"\"\"Crear datos para gr√°fico de fuerza dirigida\"\"\"\n",
    "    \n",
    "    # Simular posiciones basadas en centralidad y conexiones\n",
    "    node_positions = {}\n",
    "    \n",
    "    # Posicionar nodos de contenido en el centro\n",
    "    content_nodes = [node for node, attrs in network_graph.nodes.items() if attrs.get('type') == 'content']\n",
    "    user_nodes = [node for node, attrs in network_graph.nodes.items() if attrs.get('type') == 'user']\n",
    "    \n",
    "    # Posicionar contenido en c√≠rculo central\n",
    "    for i, content in enumerate(content_nodes):\n",
    "        angle = (2 * math.pi * i) / len(content_nodes)\n",
    "        node_positions[content] = {\n",
    "            'x': 0.5 + 0.2 * math.cos(angle),\n",
    "            'y': 0.5 + 0.2 * math.sin(angle),\n",
    "            'type': 'content',\n",
    "            'centrality': network_graph.degree_centrality(content)\n",
    "        }\n",
    "    \n",
    "    # Posicionar usuarios alrededor del contenido\n",
    "    for i, user in enumerate(user_nodes):\n",
    "        # Obtener contenido preferido del usuario\n",
    "        neighbors = network_graph.get_neighbors(user)\n",
    "        if neighbors:\n",
    "            # Posicionar cerca del contenido m√°s conectado\n",
    "            preferred_content = max(neighbors, key=lambda x: x[1])[0]\n",
    "            base_pos = node_positions[preferred_content]\n",
    "            \n",
    "            # Agregar variaci√≥n aleatoria\n",
    "            angle = random.uniform(0, 2 * math.pi)\n",
    "            distance = random.uniform(0.3, 0.5)\n",
    "            \n",
    "            node_positions[user] = {\n",
    "                'x': base_pos['x'] + distance * math.cos(angle),\n",
    "                'y': base_pos['y'] + distance * math.sin(angle),\n",
    "                'type': 'user',\n",
    "                'region': network_graph.nodes[user].get('region', 'Other'),\n",
    "                'centrality': network_graph.degree_centrality(user)\n",
    "            }\n",
    "        else:\n",
    "            # Posici√≥n aleatoria si no hay conexiones\n",
    "            node_positions[user] = {\n",
    "                'x': random.uniform(0, 1),\n",
    "                'y': random.uniform(0, 1),\n",
    "                'type': 'user',\n",
    "                'region': network_graph.nodes[user].get('region', 'Other'),\n",
    "                'centrality': 0\n",
    "            }\n",
    "    \n",
    "    return node_positions\n",
    "\n",
    "# Crear datos de fuerza dirigida\n",
    "force_directed_data = create_force_directed_data(network_graph)\n",
    "\n",
    "print(f\"üìä Datos de fuerza dirigida creados:\")\n",
    "print(f\"  Nodos posicionados: {len(force_directed_data)}\")\n",
    "\n",
    "# An√°lisis de clusters visuales\n",
    "content_clusters = defaultdict(list)\n",
    "for node, pos in force_directed_data.items():\n",
    "    if pos['type'] == 'user':\n",
    "        # Encontrar contenido m√°s cercano\n",
    "        min_distance = float('inf')\n",
    "        closest_content = None\n",
    "        \n",
    "        for content_node, content_pos in force_directed_data.items():\n",
    "            if content_pos['type'] == 'content':\n",
    "                distance = math.sqrt((pos['x'] - content_pos['x'])**2 + (pos['y'] - content_pos['y'])**2)\n",
    "                if distance < min_distance:\n",
    "                    min_distance = distance\n",
    "                    closest_content = content_node\n",
    "        \n",
    "        if closest_content:\n",
    "            content_clusters[closest_content].append(node)\n",
    "\n",
    "print(\"\\nüìä Clusters visuales por contenido:\")\n",
    "for content, users in content_clusters.items():\n",
    "    print(f\"  {content}: {len(users)} usuarios cercanos\")\n",
    "\n",
    "print(f\"\\n‚úÖ Datos de fuerza dirigida preparados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# CELDA 7: ADJACENCY MATRIX HEATMAP - Matriz de Conexiones\n",
    "# ======================================================================\n",
    "\n",
    "print(\"üî• ADJACENCY MATRIX HEATMAP: Matriz de Conexiones\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def create_adjacency_matrix(user_content_data):\n",
    "    \"\"\"Crear matriz de adyacencia usuario-contenido\"\"\"\n",
    "    \n",
    "    # Obtener usuarios y contenido √∫nicos\n",
    "    users = sorted(set(d['user_id'] for d in user_content_data))\n",
    "    content_categories = sorted(set(d['content_category'] for d in user_content_data))\n",
    "    \n",
    "    # Crear matriz de conexiones\n",
    "    adjacency_matrix = {}\n",
    "    for user in users:\n",
    "        adjacency_matrix[user] = {}\n",
    "        for content in content_categories:\n",
    "            adjacency_matrix[user][content] = 0\n",
    "    \n",
    "    # Llenar matriz con datos reales\n",
    "    for data in user_content_data:\n",
    "        user = data['user_id']\n",
    "        content = data['content_category']\n",
    "        interest = data['interest']\n",
    "        \n",
    "        # Normalizar inter√©s a escala 0-1\n",
    "        normalized_interest = min(interest / 100.0, 1.0)\n",
    "        adjacency_matrix[user][content] = normalized_interest\n",
    "    \n",
    "    return adjacency_matrix, users, content_categories\n",
    "\n",
    "# Crear matriz de adyacencia\n",
    "adjacency_matrix, users, content_categories = create_adjacency_matrix(user_content_data)\n",
    "\n",
    "print(f\"üìä Matriz de adyacencia creada:\")\n",
    "print(f\"  Usuarios: {len(users)}\")\n",
    "print(f\"  Categor√≠as de contenido: {len(content_categories)}\")\n",
    "print(f\"  Dimensiones: {len(users)} x {len(content_categories)}\")\n",
    "\n",
    "# An√°lisis de la matriz\n",
    "print(\"\\nüìä An√°lisis de conexiones por usuario:\")\n",
    "user_connection_strengths = {}\n",
    "for user in users[:10]:  # Mostrar solo los primeros 10 usuarios\n",
    "    total_connection = sum(adjacency_matrix[user].values())\n",
    "    user_connection_strengths[user] = total_connection\n",
    "    print(f\"  {user}: {total_connection:.2f} (conexi√≥n total)\")\n",
    "\n",
    "print(\"\\nüìä An√°lisis de conexiones por contenido:\")\n",
    "content_connection_strengths = {}\n",
    "for content in content_categories:\n",
    "    total_connection = sum(adjacency_matrix[user][content] for user in users)\n",
    "    content_connection_strengths[content] = total_connection\n",
    "    print(f\"  {content}: {total_connection:.2f} (conexi√≥n total)\")\n",
    "\n",
    "print(f\"\\n‚úÖ Matriz de adyacencia preparada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# CELDA 8: CHORD DIAGRAM - Patrones de Co-visualizaci√≥n\n",
    "# ======================================================================\n",
    "\n",
    "print(\"üéµ CHORD DIAGRAM: Patrones de Co-visualizaci√≥n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def create_chord_diagram_data(user_content_data):\n",
    "    \"\"\"Crear datos para diagrama de cuerdas de co-visualizaci√≥n\"\"\"\n",
    "    \n",
    "    # Agrupar usuarios por contenido\n",
    "    content_users = defaultdict(set)\n",
    "    for data in user_content_data:\n",
    "        if data['interest'] > 20:  # Umbral de inter√©s\n",
    "            content_users[data['content_category']].add(data['user_id'])\n",
    "    \n",
    "    # Calcular similitudes entre contenidos\n",
    "    similarities = {}\n",
    "    content_list = list(content_users.keys())\n",
    "    \n",
    "    for i, content1 in enumerate(content_list):\n",
    "        for j, content2 in enumerate(content_list):\n",
    "            if i != j:\n",
    "                users1 = content_users[content1]\n",
    "                users2 = content_users[content2]\n",
    "                \n",
    "                # Calcular similitud de Jaccard\n",
    "                intersection = len(users1.intersection(users2))\n",
    "                union = len(users1.union(users2))\n",
    "                similarity = intersection / union if union > 0 else 0\n",
    "                \n",
    "                similarities[(content1, content2)] = similarity\n",
    "    \n",
    "    return similarities, content_users\n",
    "\n",
    "# Crear datos del diagrama de cuerdas\n",
    "chord_similarities, content_users = create_chord_diagram_data(user_content_data)\n",
    "\n",
    "print(f\"üìä Patrones de co-visualizaci√≥n analizados:\")\n",
    "print(f\"  Categor√≠as de contenido: {len(content_users)}\")\n",
    "print(f\"  Similitudes calculadas: {len(chord_similarities)}\")\n",
    "\n",
    "print(\"\\nüî∏ Pares con mayor similitud de audiencia:\")\n",
    "sorted_similarities = sorted(chord_similarities.items(), key=lambda x: x[1], reverse=True)\n",
    "for (content1, content2), similarity in sorted_similarities:\n",
    "    if similarity > 0.1:  # Solo mostrar similitudes significativas\n",
    "        print(f\"  {content1} ‚Üî {content2}: {similarity:.3f}\")\n",
    "\n",
    "print(\"\\nüìä Audiencia por categor√≠a de contenido:\")\n",
    "for content, users in content_users.items():\n",
    "    print(f\"  {content}: {len(users)} usuarios √∫nicos\")\n",
    "\n",
    "print(f\"\\n‚úÖ Datos del diagrama de cuerdas preparados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# CELDA 9: GRAPH METRICS DASHBOARD - M√©tricas de Red\n",
    "# ======================================================================\n",
    "\n",
    "print(\"üìä GRAPH METRICS DASHBOARD: M√©tricas de Red\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def calculate_graph_metrics(network_graph, user_content_data):\n",
    "    \"\"\"Calcular m√©tricas de red\"\"\"\n",
    "    \n",
    "    metrics = {\n",
    "        'total_nodes': len(network_graph.nodes),\n",
    "        'total_edges': len(network_graph.edges),\n",
    "        'density': network_graph.density(),\n",
    "        'user_nodes': len([n for n, attrs in network_graph.nodes.items() if attrs.get('type') == 'user']),\n",
    "        'content_nodes': len([n for n, attrs in network_graph.nodes.items() if attrs.get('type') == 'content']),\n",
    "        'avg_connections_per_user': 0,\n",
    "        'avg_connections_per_content': 0,\n",
    "        'strong_connections': 0,\n",
    "        'weak_connections': 0\n",
    "    }\n",
    "    \n",
    "    # Calcular conexiones promedio\n",
    "    user_connections = 0\n",
    "    content_connections = 0\n",
    "    \n",
    "    for node, attrs in network_graph.nodes.items():\n",
    "        neighbors = network_graph.get_neighbors(node)\n",
    "        if attrs.get('type') == 'user':\n",
    "            user_connections += len(neighbors)\n",
    "        elif attrs.get('type') == 'content':\n",
    "            content_connections += len(neighbors)\n",
    "    \n",
    "    if metrics['user_nodes'] > 0:\n",
    "        metrics['avg_connections_per_user'] = user_connections / metrics['user_nodes']\n",
    "    \n",
    "    if metrics['content_nodes'] > 0:\n",
    "        metrics['avg_connections_per_content'] = content_connections / metrics['content_nodes']\n",
    "    \n",
    "    # Clasificar conexiones por fuerza\n",
    "    for edge in network_graph.edges:\n",
    "        weight = edge[2]\n",
    "        if weight > 0.5:\n",
    "            metrics['strong_connections'] += 1\n",
    "        else:\n",
    "            metrics['weak_connections'] += 1\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Calcular m√©tricas\n",
    "graph_metrics = calculate_graph_metrics(network_graph, user_content_data)\n",
    "\n",
    "print(f\"üìä M√©tricas de la red:\")\n",
    "print(f\"  Nodos totales: {graph_metrics['total_nodes']}\")\n",
    "print(f\"  Aristas totales: {graph_metrics['total_edges']}\")\n",
    "print(f\"  Densidad: {graph_metrics['density']:.3f}\")\n",
    "print(f\"  Nodos de usuario: {graph_metrics['user_nodes']}\")\n",
    "print(f\"  Nodos de contenido: {graph_metrics['content_nodes']}\")\n",
    "print(f\"  Conexiones promedio por usuario: {graph_metrics['avg_connections_per_user']:.2f}\")\n",
    "print(f\"  Conexiones promedio por contenido: {graph_metrics['avg_connections_per_content']:.2f}\")\n",
    "print(f\"  Conexiones fuertes: {graph_metrics['strong_connections']}\")\n",
    "print(f\"  Conexiones d√©biles: {graph_metrics['weak_connections']}\")\n",
    "\n",
    "# An√°lisis de centralidad\n",
    "print(\"\\nüìà An√°lisis de centralidad:\")\n",
    "centrality_scores = {}\n",
    "for node, attrs in network_graph.nodes.items():\n",
    "    centrality = network_graph.degree_centrality(node)\n",
    "    centrality_scores[node] = centrality\n",
    "\n",
    "# Top nodos m√°s centrales\n",
    "top_central_nodes = sorted(centrality_scores.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "print(\"\\nüî∏ Top 10 nodos m√°s centrales:\")\n",
    "for node, centrality in top_central_nodes:\n",
    "    node_type = network_graph.nodes[node].get('type', 'unknown')\n",
    "    print(f\"  {node} ({node_type}): {centrality:.3f}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Dashboard de m√©tricas completado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# CELDA 10: An√°lisis de Insights y Recomendaciones\n",
    "# ======================================================================\n",
    "\n",
    "print(\"üí° AN√ÅLISIS DE INSIGHTS Y RECOMENDACIONES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# An√°lisis de la red\n",
    "print(\"\\nüï∏Ô∏è INSIGHTS DE LA RED:\")\n",
    "\n",
    "# Contenido m√°s central\n",
    "most_central_content = max(content_centrality.items(), key=lambda x: x[1])\n",
    "print(f\"‚Ä¢ Contenido m√°s central: {most_central_content[0]} (centralidad: {most_central_content[1]:.3f})\")\n",
    "\n",
    "# Comunidad m√°s grande\n",
    "largest_community = max(communities, key=lambda x: x['size'])\n",
    "print(f\"‚Ä¢ Comunidad m√°s grande: {largest_community['id']} ({largest_community['size']} usuarios)\")\n",
    "print(f\"  - Contenido preferido: {largest_community['preferred_content']}\")\n",
    "print(f\"  - Inter√©s promedio: {largest_community['avg_interest']:.1f}\")\n",
    "\n",
    "# Densidad de la red\n",
    "print(f\"‚Ä¢ Densidad de la red: {graph_metrics['density']:.3f}\")\n",
    "if graph_metrics['density'] > 0.1:\n",
    "    print(\"  - Red bien conectada, buenas oportunidades de recomendaci√≥n cruzada\")\n",
    "else:\n",
    "    print(\"  - Red dispersa, oportunidades de conectar usuarios similares\")\n",
    "\n",
    "# An√°lisis de co-visualizaci√≥n\n",
    "print(\"\\nüéµ INSIGHTS DE CO-VISUALIZACI√ìN:\")\n",
    "\n",
    "# Mayor similitud de audiencia\n",
    "if chord_similarities:\n",
    "    strongest_similarity = max(chord_similarities.items(), key=lambda x: x[1])\n",
    "    print(f\"‚Ä¢ Mayor similitud de audiencia: {strongest_similarity[0][0]} ‚Üî {strongest_similarity[0][1]} ({strongest_similarity[1]:.3f})\")\n",
    "    \n",
    "    # Recomendaciones basadas en similitud\n",
    "    if strongest_similarity[1] > 0.3:\n",
    "        print(f\"  - Oportunidad de recomendaci√≥n cruzada entre {strongest_similarity[0][0]} y {strongest_similarity[0][1]}\")\n",
    "\n",
    "# An√°lisis de comunidades\n",
    "print(\"\\nüë• INSIGHTS DE COMUNIDADES:\")\n",
    "\n",
    "# Comunidad m√°s diversa geogr√°ficamente\n",
    "most_diverse_community = max(communities, key=lambda x: len(x['regions']))\n",
    "print(f\"‚Ä¢ Comunidad m√°s diversa: {most_diverse_community['id']} ({len(most_diverse_community['regions'])} regiones)\")\n",
    "\n",
    "# Comunidad con mayor volatilidad (tendencias)\n",
    "most_volatile_community = max(communities, key=lambda x: x['avg_volatility'])\n",
    "print(f\"‚Ä¢ Comunidad m√°s vol√°til: {most_volatile_community['id']} (volatilidad: {most_volatile_community['avg_volatility']:.3f})\")\n",
    "\n",
    "# Recomendaciones\n",
    "print(\"\\nüéØ RECOMENDACIONES:\")\n",
    "print(f\"\\n1. ALGORITMOS DE RECOMENDACI√ìN:\")\n",
    "print(f\"   ‚Ä¢ Personalizar por comunidad: {largest_community['preferred_content']}\")\n",
    "print(f\"   ‚Ä¢ Implementar recomendaciones cruzadas para {most_central_content[0]}\")\n",
    "print(f\"   ‚Ä¢ Usar similitud de audiencia para {strongest_similarity[0][0]} ‚Üî {strongest_similarity[0][1]}\")\n",
    "\n",
    "print(f\"\\n2. ESTRATEGIA DE CONTENIDO:\")\n",
    "print(f\"   ‚Ä¢ Priorizar {most_central_content[0]} en algoritmos de recomendaci√≥n\")\n",
    "print(f\"   ‚Ä¢ Desarrollar contenido puente entre {strongest_similarity[0][0]} y {strongest_similarity[0][1]}\")\n",
    "print(f\"   ‚Ä¢ Monitorear tendencias en {most_volatile_community['preferred_content']}\")\n",
    "\n",
    "print(f\"\\n3. EXPANSI√ìN DE AUDIENCIA:\")\n",
    "print(f\"   ‚Ä¢ Enfocar en {most_diverse_community['preferred_content']} para expansi√≥n global\")\n",
    "print(f\"   ‚Ä¢ Crear campa√±as dirigidas a comunidades de {largest_community['preferred_content']}\")\n",
    "print(f\"   ‚Ä¢ Desarrollar contenido h√≠brido para conectar comunidades\")\n",
    "\n",
    "# Guardar resultados\n",
    "results = {\n",
    "    'network_insights': {\n",
    "        'most_central_content': most_central_content[0],\n",
    "        'largest_community': largest_community['id'],\n",
    "        'network_density': graph_metrics['density'],\n",
    "        'strongest_similarity': strongest_similarity[0] if chord_similarities else None\n",
    "    },\n",
    "    'community_insights': {\n",
    "        'most_diverse_community': most_diverse_community['id'],\n",
    "        'most_volatile_community': most_volatile_community['id'],\n",
    "        'total_communities': len(communities)\n",
    "    },\n",
    "    'raw_data': {\n",
    "        'network_graph': {\n",
    "            'nodes': len(network_graph.nodes),\n",
    "            'edges': len(network_graph.edges),\n",
    "            'density': graph_metrics['density']\n",
    "        },\n",
    "        'communities': [{\n",
    "            'id': c['id'],\n",
    "            'size': c['size'],\n",
    "            'preferred_content': c['preferred_content'],\n",
    "            'avg_interest': c['avg_interest'],\n",
    "            'regions': dict(c['regions'])\n",
    "        } for c in communities],\n",
    "        'chord_similarities': dict(chord_similarities),\n",
    "        'content_centrality': content_centrality\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('phase2_relational_results_updated.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2, default=str)\n",
    "\n",
    "print(\"\\n‚úÖ Resultados guardados en: phase2_relational_results_updated.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# CELDA 11: RESUMEN Y BIG IDEA DE LA FASE 2\n",
    "# ======================================================================\n",
    "\n",
    "print(\"üéØ RESUMEN DE LA FASE 2: AN√ÅLISIS RELACIONAL (ACTUALIZADO)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüìä AN√ÅLISIS COMPLETADOS:\")\n",
    "print(\"‚úÖ 1. Network Graph: Conexiones usuario-contenido\")\n",
    "print(\"‚úÖ 2. Community Detection: Clusters de usuarios\")\n",
    "print(\"‚úÖ 3. Force-Directed Graph: Visualizaci√≥n de conexiones\")\n",
    "print(\"‚úÖ 4. Adjacency Matrix Heatmap: Matriz de conexiones\")\n",
    "print(\"‚úÖ 5. Chord Diagram: Patrones de co-visualizaci√≥n\")\n",
    "print(\"‚úÖ 6. Graph Metrics Dashboard: M√©tricas de red\")\n",
    "\n",
    "print(\"\\nüîç INSIGHTS PRINCIPALES:\")\n",
    "print(f\"‚Ä¢ Contenido m√°s central: {most_central_content[0]} (centralidad: {most_central_content[1]:.3f})\")\n",
    "print(f\"‚Ä¢ Comunidad m√°s grande: {largest_community['id']} ({largest_community['size']} usuarios)\")\n",
    "print(f\"‚Ä¢ Densidad de red: {graph_metrics['density']:.3f}\")\n",
    "if chord_similarities:\n",
    "    print(f\"‚Ä¢ Mayor similitud de audiencia: {strongest_similarity[0][0]} ‚Üî {strongest_similarity[0][1]} ({strongest_similarity[1]:.3f})\")\n",
    "print(f\"‚Ä¢ Comunidades detectadas: {len(communities)}\")\n",
    "\n",
    "print(\"\\nüí° BIG IDEA:\")\n",
    "print(f\"Nuestro an√°lisis relacional revela que los usuarios forman comunidades\")\n",
    "print(f\"distintas basadas en preferencias de contenido, con {most_central_content[0]} como\")\n",
    "print(f\"contenido m√°s central. Debemos personalizar algoritmos de recomendaci√≥n\")\n",
    "print(f\"por comunidad y aprovechar contenido puente para expandir audiencias\")\n",
    "print(f\"y maximizar el engagement.\")\n",
    "\n",
    "print(\"\\nüìÅ ARCHIVOS GENERADOS:\")\n",
    "print(\"‚Ä¢ phase2_relational_results_updated.json\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FASE 2 COMPLETADA EXITOSAMENTE (ACTUALIZADA CON DATOS REALES)\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
